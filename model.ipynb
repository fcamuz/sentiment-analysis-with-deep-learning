{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis with Deep Learning\n",
    "\n",
    "# Phase 2- Modelling\n",
    "\n",
    "This notebook consists the functions and code for modelling.  \n",
    "\n",
    "### CHRISP-DM phases\n",
    "\n",
    "Modelling and Evaluation phases for CRISP-DM can be found in this noteboook.\n",
    "\n",
    "#### 4.Modeling\n",
    "Modeling techniques are selected and applied. \n",
    "\n",
    "#### 5.Evaluation\n",
    "Once one or more models have been built that appear to have high quality based on whichever loss functions have been selected, these need to be tested to ensure they generalize against unseen data and that all key business issues have been sufficiently considered.  The end result is the selection of the champion model(s).\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "- 1.Import Libraries\n",
    "- 2.Define Functions \n",
    "- 3.Modeling With Neural Networks  \n",
    "- 4.Tuning the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn')\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from nltk import word_tokenize, FreqDist\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from gensim.models import Word2Vec\n",
    "np.random.seed(0)\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model, Sequential, Input\n",
    "from keras.layers import Dense, Embedding, Input, Conv1D, GlobalMaxPool1D, GlobalAveragePooling1D, Dropout, concatenate, Layer, InputSpec, CuDNNLSTM, SpatialDropout1D, Activation, LSTM\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from keras import activations, initializers, regularizers, constraints, optimizers, layers\n",
    "from keras.utils.conv_utils import conv_output_length\n",
    "from keras.regularizers import l2\n",
    "from keras.constraints import maxnorm\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing import text, sequence\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, SpatialDropout1D, Activation\n",
    "from keras.layers import Conv1D, Bidirectional, GlobalMaxPool1D, MaxPooling1D, BatchNormalization\n",
    "from keras.optimizers import Adam, SGD\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of unique words we want to use (or: number of rows in incoming embedding vector)\n",
    "max_features = 8192\n",
    "# max number of words in a comment to use (or: number of columns in incoming embedding vector)\n",
    "max_len = 128\n",
    "# dimension of the embedding variable (or: number of rows in output of embedding vector)\n",
    "embedding_dims = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_smalldata ( ):\n",
    "    # Loading partial train test files , tokenized, sequenzed and padded\n",
    "    pickle_in = open(\"data/vectors_small/X_train2_file.pickle\",\"rb\")\n",
    "    X_train2 = pickle.load(pickle_in)\n",
    "\n",
    "    pickle_in = open(\"data/vectors_small/X_test2_file.pickle\",\"rb\")\n",
    "    X_test2 = pickle.load(pickle_in)\n",
    "\n",
    "    pickle_in = open(\"data/vectors_small/y_train2_file.pickle\",\"rb\")\n",
    "    y_train2 = pickle.load(pickle_in)\n",
    "\n",
    "    pickle_in = open(\"data/vectors_small/y_test2_file.pickle\",\"rb\")\n",
    "    y_test2 = pickle.load(pickle_in)\n",
    "    \n",
    "    return X_train2, X_test2, y_train2, y_test2\n",
    "\n",
    "\n",
    "def load_tokenizer():\n",
    "    with open('tokenizer.pickle', 'rb') as handle:\n",
    "        tokenizer=pickle.load(handle)\n",
    "        return tokenizer\n",
    "    \n",
    "def create_model ( hidden_layers, \n",
    "                  loss='binary_crossentropy',\n",
    "                  optimizer=Adam(0.01),\n",
    "                  metrics=['accuracy'],\n",
    "                  embedding_matrix=None,\n",
    "                  max_len=max_len,\n",
    "                  embedding_dims=embedding_dims,\n",
    "                  max_features=max_features,\n",
    "                  glove=False,\n",
    "                 ):\n",
    " \n",
    "    # check if embedding matrix has assigned which means the model uses glove embeddings \n",
    "    if glove==False:\n",
    "        emb_layer=Embedding(input_dim=max_features, input_length=max_len,\n",
    "                        output_dim=embedding_dims)\n",
    "    else:\n",
    "        \n",
    "        emb_layer=Embedding(input_dim =embedding_matrix.shape[0], input_length=max_len,\n",
    "                          output_dim=embedding_matrix.shape[1], \n",
    "                          weights=[embedding_matrix], trainable=False)\n",
    "    \n",
    "    # instantiate Sequential model\n",
    "    model = Sequential()\n",
    " \n",
    "    # add embedding layer with defined parameters\n",
    "    model.add(emb_layer)\n",
    "   \n",
    "    # add hidden layers available in hidden_layers list\n",
    "    for layer in hidden_layers:\n",
    "        model.add(layer)\n",
    "    \n",
    "    # add pooling layer \n",
    "    model.add(GlobalMaxPool1D())\n",
    "\n",
    "    # set the dropout layer to drop out 50% of the nodes\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    # add dense layer to produce an output dimension of 50 and using relu activation\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "\n",
    "    # finally add a dense layer\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(loss=loss,\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=metrics)\n",
    "    \n",
    "    model.summary() \n",
    "    return model\n",
    "\n",
    "\n",
    "def run_model(model, model_name, results, epochs, batch_size=32):\n",
    "    hist = model.fit(X_train2, y_train2, \n",
    "                     batch_size=batch_size, \n",
    "                     epochs=epochs, \n",
    "                     validation_split=0.1)\n",
    "\n",
    "    test_loss, test_auc = model.evaluate(X_test2, y_test2, batch_size=32)\n",
    "    print(\"-------------------------------------------\")\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    print(model_name + ' Test Loss:    ', test_loss)\n",
    "    print(model_name + ' Test Accuracy:', test_auc)\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    \n",
    "    \n",
    "    #Pass the results as key value pairs to append() function \n",
    "    row=[]\n",
    "    row =[model_name , hist.history['accuracy'][-1],\n",
    "          hist.history['val_accuracy'][-1],test_auc, test_loss] \n",
    "\n",
    "    save_model(model, model_name)\n",
    "    return row\n",
    "\n",
    "\n",
    "\n",
    "def save_model (model, model_name):\n",
    "    path=\"models/\"+model_name + \".h5\"\n",
    "    model.save(path)\n",
    "\n",
    "def save_results (results, row):\n",
    "    #Pass the results as key value pairs to append() function \n",
    "    results = results.append({'model' : row[0] , \n",
    "                        'train_acc' : row[1], \n",
    "                        'val_acc':row[2],\n",
    "                        'test_acc': row[3]\n",
    "                              \n",
    "                                    } , ignore_index=True)\n",
    "    return results\n",
    "\n",
    "\n",
    "### Loading Glove Dictionary\n",
    "def load_glove (path):\n",
    "    # load the glove840B embedding\n",
    "    embeddings_index = dict()\n",
    "    f = open(path)\n",
    "\n",
    "    for line in f:\n",
    "        # Note: use split(' ') instead of split() if you get an error\n",
    "        values = line.split(' ')\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "    f.close()\n",
    "\n",
    "    print('Loaded %s word vectors.' % len(embeddings_index))\n",
    "\n",
    "    # create a weight matrix\n",
    "    embedding_matrix = np.zeros((len(tokenizer.word_index)+1, 300))\n",
    "\n",
    "    for word, i in tokenizer.word_index.items():\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    return embedding_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Modeling With Neural Networks                       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will first try 4 different models to see which one gives the best result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set parameters for modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a dataframe to store the accuarecy results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=pd.DataFrame(columns=[\"model\", \"train_acc\",\"val_acc\" ,\"test_acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load small dataset to train and test the models\n",
    "X_train2, X_test2, y_train2, y_test2=load_smalldata()\n",
    "#load tokenizer\n",
    "tokenizer=load_tokenizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define parameters for each model such as hidden layers and glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "dnn_params={'hidden_layers':[],\n",
    "            'glove' : False,\n",
    "            'embedding_matrix':None\n",
    "           }\n",
    "\n",
    "\n",
    "cnn_params = {\n",
    "        'hidden_layers':[SpatialDropout1D(0.5),\n",
    "                   Conv1D(filters=100, kernel_size=4, padding='same', activation='relu'),\n",
    "                   BatchNormalization()],\n",
    "        'glove' : False,\n",
    "        'embedding_matrix':None}\n",
    "\n",
    "\n",
    "rnn_params ={ \n",
    "     'hidden_layers':[SpatialDropout1D(0.5),\n",
    "                  Bidirectional(LSTM(25, \n",
    "                  return_sequences=True))],\n",
    "     'glove' : False,\n",
    "     'embedding_matrix':None}\n",
    "\n",
    "#load glove embedding vectors from txt file\n",
    "embedding_matrix=load_glove (\"glove.6B.300d.txt\")\n",
    "\n",
    "cnn_glove_params ={\n",
    "    'hidden_layers':[SpatialDropout1D(0.5),\n",
    "                   Conv1D(filters=100, kernel_size=4, padding='same', activation='relu'),\n",
    "                   BatchNormalization()],\n",
    "    'glove' : True,\n",
    "    \n",
    "    'embedding_matrix':embedding_matrix\n",
    "    }\n",
    "\n",
    "rnn_glove_params ={\n",
    "    'hidden_layers':[SpatialDropout1D(0.5),\n",
    "                  Bidirectional(LSTM(25, \n",
    "                  return_sequences=True))],\n",
    "    'glove' : True,\n",
    "    'embedding_matrix':embedding_matrix\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists for model names and hiden layer\n",
    "names=[\"dnn\",\"cnn\", \"rnn\", \"cnn_glove\", \"rnn_glove\"]\n",
    "params=[dnn_params, cnn_params, rnn_params, \n",
    "        cnn_glove_params, rnn_glove_params]\n",
    "epochs=3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For loop for modelling\n",
    "\n",
    "Run a for loop to create the model, compile, fit and save results and the model itsef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name : dnn\n",
      "======================\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_9 (Embedding)      (None, 128, 64)           524288    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_9 (Glob (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 50)                3250      \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 527,589\n",
      "Trainable params: 527,589\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kaan/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 135000 samples, validate on 15000 samples\n",
      "Epoch 1/3\n",
      "135000/135000 [==============================] - 56s 414us/step - loss: 0.3914 - accuracy: 0.8251 - val_loss: 0.3244 - val_accuracy: 0.8681\n",
      "Epoch 2/3\n",
      "135000/135000 [==============================] - 59s 440us/step - loss: 0.3341 - accuracy: 0.8565 - val_loss: 0.2909 - val_accuracy: 0.8749\n",
      "Epoch 3/3\n",
      "135000/135000 [==============================] - 50s 368us/step - loss: 0.3170 - accuracy: 0.8649 - val_loss: 0.2944 - val_accuracy: 0.8757\n",
      "30000/30000 [==============================] - 2s 60us/step\n",
      "-------------------------------------------\n",
      "\n",
      "\n",
      "dnn Test Loss:     0.30266345343589784\n",
      "dnn Test Accuracy: 0.8708333373069763\n",
      "\n",
      "\n",
      "\n",
      "Model Name : cnn\n",
      "======================\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_10 (Embedding)     (None, 128, 64)           524288    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, 128, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 128, 100)          25700     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 128, 100)          400       \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_10 (Glo (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 555,489\n",
      "Trainable params: 555,289\n",
      "Non-trainable params: 200\n",
      "_________________________________________________________________\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kaan/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 135000 samples, validate on 15000 samples\n",
      "Epoch 1/3\n",
      "135000/135000 [==============================] - 206s 2ms/step - loss: 0.3754 - accuracy: 0.8282 - val_loss: 0.2835 - val_accuracy: 0.8812\n",
      "Epoch 2/3\n",
      "135000/135000 [==============================] - 182s 1ms/step - loss: 0.2934 - accuracy: 0.8795 - val_loss: 0.2708 - val_accuracy: 0.8869\n",
      "Epoch 3/3\n",
      "135000/135000 [==============================] - 186s 1ms/step - loss: 0.2737 - accuracy: 0.8893 - val_loss: 0.2679 - val_accuracy: 0.8879\n",
      "30000/30000 [==============================] - 10s 320us/step\n",
      "-------------------------------------------\n",
      "\n",
      "\n",
      "cnn Test Loss:     0.2730163905858993\n",
      "cnn Test Accuracy: 0.8843333125114441\n",
      "\n",
      "\n",
      "\n",
      "Model Name : rnn\n",
      "======================\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_11 (Embedding)     (None, 128, 64)           524288    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_2 (Spatial (None, 128, 64)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 128, 50)           18000     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_11 (Glo (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 544,889\n",
      "Trainable params: 544,889\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kaan/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 135000 samples, validate on 15000 samples\n",
      "Epoch 1/3\n",
      "135000/135000 [==============================] - 636s 5ms/step - loss: 0.4429 - accuracy: 0.7929 - val_loss: 0.3318 - val_accuracy: 0.8555\n",
      "Epoch 2/3\n",
      "135000/135000 [==============================] - 568s 4ms/step - loss: 0.3793 - accuracy: 0.8332 - val_loss: 0.3119 - val_accuracy: 0.8665\n",
      "Epoch 3/3\n",
      "135000/135000 [==============================] - 557s 4ms/step - loss: 0.3580 - accuracy: 0.8445 - val_loss: 0.3095 - val_accuracy: 0.8697\n",
      "30000/30000 [==============================] - 28s 930us/step\n",
      "-------------------------------------------\n",
      "\n",
      "\n",
      "rnn Test Loss:     0.31319638199806216\n",
      "rnn Test Accuracy: 0.8661333322525024\n",
      "\n",
      "\n",
      "\n",
      "Model Name : cnn_glove\n",
      "======================\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_12 (Embedding)     (None, 128, 300)          263894100 \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_3 (Spatial (None, 128, 300)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 128, 100)          120100    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 128, 100)          400       \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_12 (Glo (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 264,019,701\n",
      "Trainable params: 125,401\n",
      "Non-trainable params: 263,894,300\n",
      "_________________________________________________________________\n",
      "3\n",
      "Train on 135000 samples, validate on 15000 samples\n",
      "Epoch 1/3\n",
      "135000/135000 [==============================] - 336s 2ms/step - loss: 0.4299 - accuracy: 0.8053 - val_loss: 0.3387 - val_accuracy: 0.8591\n",
      "Epoch 2/3\n",
      "135000/135000 [==============================] - 327s 2ms/step - loss: 0.3971 - accuracy: 0.8234 - val_loss: 0.3422 - val_accuracy: 0.8629\n",
      "Epoch 3/3\n",
      "135000/135000 [==============================] - 326s 2ms/step - loss: 0.3881 - accuracy: 0.8277 - val_loss: 0.3142 - val_accuracy: 0.8676\n",
      "30000/30000 [==============================] - 30s 992us/step\n",
      "-------------------------------------------\n",
      "\n",
      "\n",
      "cnn_glove Test Loss:     0.3151964765071869\n",
      "cnn_glove Test Accuracy: 0.866599977016449\n",
      "\n",
      "\n",
      "\n",
      "Model Name : rnn_glove\n",
      "======================\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_13 (Embedding)     (None, 128, 300)          263894100 \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_4 (Spatial (None, 128, 300)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 128, 50)           65200     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_13 (Glo (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 263,961,901\n",
      "Trainable params: 67,801\n",
      "Non-trainable params: 263,894,100\n",
      "_________________________________________________________________\n",
      "3\n",
      "Train on 135000 samples, validate on 15000 samples\n",
      "Epoch 1/3\n",
      "135000/135000 [==============================] - 586s 4ms/step - loss: 0.4333 - accuracy: 0.8015 - val_loss: 0.3634 - val_accuracy: 0.8462\n",
      "Epoch 2/3\n",
      "135000/135000 [==============================] - 584s 4ms/step - loss: 0.4110 - accuracy: 0.8135 - val_loss: 0.3527 - val_accuracy: 0.8485\n",
      "Epoch 3/3\n",
      "135000/135000 [==============================] - 585s 4ms/step - loss: 0.4052 - accuracy: 0.8160 - val_loss: 0.3415 - val_accuracy: 0.8527\n",
      "30000/30000 [==============================] - 53s 2ms/step\n",
      "-------------------------------------------\n",
      "\n",
      "\n",
      "rnn_glove Test Loss:     0.3426892470518748\n",
      "rnn_glove Test Accuracy: 0.8519999980926514\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#set epochs to 3\n",
    "#Run a for loop to create the model, compile, fit and save results \n",
    "#and save the model to models folder\n",
    "for name, param in zip(names, params):\n",
    "    print(\"Model Name :\", name)\n",
    "    print(\"======================\")\n",
    "    model=create_model(hidden_layers=param['hidden_layers'], \n",
    "                   glove=param['glove'],\n",
    "                   embedding_matrix=param['embedding_matrix']\n",
    "                    )\n",
    "    row=run_model(model, name, results, epochs)\n",
    "    results=save_results(results, row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking results and picking the model for tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>test_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>dnn</td>\n",
       "      <td>0.864948</td>\n",
       "      <td>0.875733</td>\n",
       "      <td>0.870833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>cnn</td>\n",
       "      <td>0.889348</td>\n",
       "      <td>0.887933</td>\n",
       "      <td>0.884333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>rnn</td>\n",
       "      <td>0.844452</td>\n",
       "      <td>0.869733</td>\n",
       "      <td>0.866133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>cnn_glove</td>\n",
       "      <td>0.827726</td>\n",
       "      <td>0.867600</td>\n",
       "      <td>0.866600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>rnn_glove</td>\n",
       "      <td>0.816000</td>\n",
       "      <td>0.852733</td>\n",
       "      <td>0.852000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       model  train_acc   val_acc  test_acc\n",
       "0        dnn   0.864948  0.875733  0.870833\n",
       "1        cnn   0.889348  0.887933  0.884333\n",
       "2        rnn   0.844452  0.869733  0.866133\n",
       "3  cnn_glove   0.827726  0.867600  0.866600\n",
       "4  rnn_glove   0.816000  0.852733  0.852000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on this results CNN is the best performing model so far. From this forward, I will tune only this model and try to impove its performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Tuning the Best Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iteration 1:  CNN with SGD optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use a different optimizer for the same model structure. I will use SGD.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = optimizers.SGD(lr=0.05, decay=1e-6, momentum=0.5, nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_14 (Embedding)     (None, 128, 64)           524288    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_6 (Spatial (None, 128, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 128, 100)          25700     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 128, 100)          400       \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_14 (Glo (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 555,489\n",
      "Trainable params: 555,289\n",
      "Non-trainable params: 200\n",
      "_________________________________________________________________\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kaan/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 135000 samples, validate on 15000 samples\n",
      "Epoch 1/3\n",
      "135000/135000 [==============================] - 156s 1ms/step - loss: 0.4958 - accuracy: 0.7368 - val_loss: 0.3542 - val_accuracy: 0.8494\n",
      "Epoch 2/3\n",
      "135000/135000 [==============================] - 148s 1ms/step - loss: 0.3541 - accuracy: 0.8474 - val_loss: 0.3149 - val_accuracy: 0.8705\n",
      "Epoch 3/3\n",
      "135000/135000 [==============================] - 157s 1ms/step - loss: 0.3247 - accuracy: 0.8637 - val_loss: 0.3312 - val_accuracy: 0.8749\n",
      "30000/30000 [==============================] - 10s 317us/step\n",
      "-------------------------------------------\n",
      "\n",
      "\n",
      "cnn_glove_sgd Test Loss:     0.33474224851926165\n",
      "cnn_glove_sgd Test Accuracy: 0.8713666796684265\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# iteration 1 = with sgd optimizer\n",
    "model=create_model(hidden_layers=[SpatialDropout1D(0.5),\n",
    "                        Conv1D(filters=100,kernel_size=4, padding='same', activation='relu'),\n",
    "                        BatchNormalization()],\n",
    "                   \n",
    "                      glove = False,\n",
    "                      embedding_matrix=None,\n",
    "                      optimizer = sgd)\n",
    "row=run_model(model, \"cnn_glove_sgd\", results, epochs)\n",
    "\n",
    "results=save_results(results, row)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SGD optimizer did not perform better than \"adam\". So lets stick with \"adam\" optimizer.  \n",
    "\n",
    "## Iteration 2:  CNN with 2 convolution layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_20 (Embedding)     (None, 128, 64)           524288    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_13 (Spatia (None, 128, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 128, 100)          25700     \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 128, 100)          400       \n",
      "_________________________________________________________________\n",
      "conv1d_15 (Conv1D)           (None, 128, 100)          40100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 128, 100)          400       \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_19 (Glo (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 595,989\n",
      "Trainable params: 595,589\n",
      "Non-trainable params: 400\n",
      "_________________________________________________________________\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kaan/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 135000 samples, validate on 15000 samples\n",
      "Epoch 1/3\n",
      "135000/135000 [==============================] - 342s 3ms/step - loss: 0.6993 - accuracy: 0.5014 - val_loss: 0.6931 - val_accuracy: 0.5012\n",
      "Epoch 2/3\n",
      "135000/135000 [==============================] - 356s 3ms/step - loss: 0.6934 - accuracy: 0.5003 - val_loss: 0.6932 - val_accuracy: 0.5012\n",
      "Epoch 3/3\n",
      "135000/135000 [==============================] - 317s 2ms/step - loss: 0.6935 - accuracy: 0.4994 - val_loss: 0.6931 - val_accuracy: 0.5012\n",
      "30000/30000 [==============================] - 20s 669us/step\n",
      "-------------------------------------------\n",
      "\n",
      "\n",
      "cnn_2cnv Test Loss:     0.6931803480148315\n",
      "cnn_2cnv Test Accuracy: 0.4967666566371918\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# iteration 1 = with sgd optimizer\n",
    "model=create_model(hidden_layers=[SpatialDropout1D(0.5),\n",
    "                        Conv1D(filters=100,kernel_size=4, padding='same', activation='relu'),\n",
    "                        BatchNormalization(),\n",
    "                        Conv1D(filters=100,kernel_size=4, padding='same', activation='relu'),\n",
    "                        BatchNormalization()],\n",
    "                        glove =False,\n",
    "                        embedding_matrix=None,\n",
    "                      )\n",
    "epochs=3\n",
    "row=run_model(model, \"cnn_2cnv\", results, epochs)\n",
    "\n",
    "results=save_results(results, row)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the second convolution layer cnn model did not learn at all. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding a 2nd convolution layer did not improved the model. \n",
    "\n",
    "## Iteration 3:  CNN_Glove  with more epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_26 (Embedding)     (None, 128, 64)           524288    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_22 (Spatia (None, 128, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, 128, 100)          25700     \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 128, 100)          400       \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_25 (Glo (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 555,489\n",
      "Trainable params: 555,289\n",
      "Non-trainable params: 200\n",
      "_________________________________________________________________\n",
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kaan/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 135000 samples, validate on 15000 samples\n",
      "Epoch 1/8\n",
      "135000/135000 [==============================] - 173s 1ms/step - loss: 0.4782 - accuracy: 0.7417 - val_loss: 0.2934 - val_accuracy: 0.8789\n",
      "Epoch 2/8\n",
      "135000/135000 [==============================] - 164s 1ms/step - loss: 0.3023 - accuracy: 0.8755 - val_loss: 0.2747 - val_accuracy: 0.8859\n",
      "Epoch 3/8\n",
      "135000/135000 [==============================] - 164s 1ms/step - loss: 0.2771 - accuracy: 0.8877 - val_loss: 0.2718 - val_accuracy: 0.8866\n",
      "Epoch 4/8\n",
      "135000/135000 [==============================] - 173s 1ms/step - loss: 0.2625 - accuracy: 0.8954 - val_loss: 0.2709 - val_accuracy: 0.8906\n",
      "Epoch 5/8\n",
      "135000/135000 [==============================] - 173s 1ms/step - loss: 0.2523 - accuracy: 0.8993 - val_loss: 0.2618 - val_accuracy: 0.8907\n",
      "Epoch 6/8\n",
      "135000/135000 [==============================] - 174s 1ms/step - loss: 0.2405 - accuracy: 0.9054 - val_loss: 0.2717 - val_accuracy: 0.8871\n",
      "Epoch 7/8\n",
      "135000/135000 [==============================] - 174s 1ms/step - loss: 0.2325 - accuracy: 0.9087 - val_loss: 0.2707 - val_accuracy: 0.8894\n",
      "Epoch 8/8\n",
      "135000/135000 [==============================] - 173s 1ms/step - loss: 0.2240 - accuracy: 0.9134 - val_loss: 0.2692 - val_accuracy: 0.8887\n",
      "30000/30000 [==============================] - 10s 332us/step\n",
      "-------------------------------------------\n",
      "\n",
      "\n",
      "cnn_glove_8epochs Test Loss:     0.2818075685540835\n",
      "cnn_glove_8epochs Test Accuracy: 0.8861666917800903\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model=create_model(hidden_layers=[SpatialDropout1D(0.5),\n",
    "                        Conv1D(filters=100, kernel_size=4, padding='same', activation='relu'),\n",
    "                        BatchNormalization()],\n",
    "                      glove = False,\n",
    "                      embedding_matrix=None)\n",
    "epochs=8\n",
    "row=run_model(model, \"cnn_glove_8epochs\", results, epochs)\n",
    "results=save_results(results, row)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>test_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>dnn</td>\n",
       "      <td>0.864948</td>\n",
       "      <td>0.875733</td>\n",
       "      <td>0.870833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>cnn</td>\n",
       "      <td>0.889348</td>\n",
       "      <td>0.887933</td>\n",
       "      <td>0.884333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>rnn</td>\n",
       "      <td>0.844452</td>\n",
       "      <td>0.869733</td>\n",
       "      <td>0.866133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>cnn_glove</td>\n",
       "      <td>0.827726</td>\n",
       "      <td>0.867600</td>\n",
       "      <td>0.866600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>rnn_glove</td>\n",
       "      <td>0.816000</td>\n",
       "      <td>0.852733</td>\n",
       "      <td>0.852000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>cnn_glove_sgd</td>\n",
       "      <td>0.863733</td>\n",
       "      <td>0.874933</td>\n",
       "      <td>0.871367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>cnn_2cnv</td>\n",
       "      <td>0.499422</td>\n",
       "      <td>0.501200</td>\n",
       "      <td>0.496767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>cnn_glove_8epochs</td>\n",
       "      <td>0.913407</td>\n",
       "      <td>0.888733</td>\n",
       "      <td>0.886167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               model  train_acc   val_acc  test_acc\n",
       "0                dnn   0.864948  0.875733  0.870833\n",
       "1                cnn   0.889348  0.887933  0.884333\n",
       "2                rnn   0.844452  0.869733  0.866133\n",
       "3          cnn_glove   0.827726  0.867600  0.866600\n",
       "4          rnn_glove   0.816000  0.852733  0.852000\n",
       "5      cnn_glove_sgd   0.863733  0.874933  0.871367\n",
       "6           cnn_2cnv   0.499422  0.501200  0.496767\n",
       "7  cnn_glove_8epochs   0.913407  0.888733  0.886167"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
